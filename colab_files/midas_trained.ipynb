{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midas trained",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLWpW1aQ6UwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cdbc202-58cb-40f6-9b62-f57d6b14deb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgcsmcI16087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b28778-7d72-46e3-d8c2-163ab10ce266"
      },
      "source": [
        "% cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7agXaV15aYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d249e9d-da03-4653-8227-9ba27f64fc44"
      },
      "source": [
        "! git clone https://github.com/intel-isl/MiDaS.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MiDaS'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 394 (delta 58), reused 201 (delta 37), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (394/394), 231.02 KiB | 4.53 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8O4jd7GhXNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286603d5-c8e5-4d99-d7c2-b00f3b14bd1c"
      },
      "source": [
        "cd /content/MiDaS/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MahTQp3RJ2ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7701f20d-8a52-40f4-ad3e-594305765318"
      },
      "source": [
        "! git checkout -b old-state b00bf61f846d73fadc1f287293648db9f88d3615"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Switched to a new branch 'old-state'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS3V-ZgH6Ot_"
      },
      "source": [
        "# ! cp /content/drive/My\\ Drive/planarcnn/8_image_0.png /content/MiDaS/input/\n",
        "# ! cp /content/drive/My\\ Drive/planarcnn/6_image_0.png /content/MiDaS/input/\n",
        "# ! cp /content /drive/My\\ Drive/output_source/image-001.jpg /content/MiDaS/input/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1CcJkYRBWtM"
      },
      "source": [
        "! cp /content/drive/My\\ Drive/pre_trained/model-f46da743.pt /content/MiDaS/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfO7_8flCA9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a3225d-d588-4da7-db12-d080eaf05269"
      },
      "source": [
        "% cd /content/MiDaS/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV0WKvJqMTE1"
      },
      "source": [
        "! mkdir ConstructionPPE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsptF6dYMsVy"
      },
      "source": [
        "# ! cp -r /content/drive/My\\ Drive/Depth\\ Images\\ using\\ MiDaS /content/MiDaS/ConstructionPPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXYvPtZaSRi4"
      },
      "source": [
        "# ! cp -r /content/drive/My\\ Drive/Annotated\\ Images/ /content/MiDaS/ConstructionPPE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3sgIjbcg-ua"
      },
      "source": [
        "! cp  /content/drive/My\\ Drive/ConstructionPPE/input_file_dir.txt /content/MiDaS/ConstructionPPE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLEfIkWEhImu"
      },
      "source": [
        "! cp  /content/drive/My\\ Drive/ConstructionPPE/MiDaS_file_dir.txt /content/MiDaS/ConstructionPPE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJcKpGOBuHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31027b7-0014-4aeb-e91f-a30feb2561a0"
      },
      "source": [
        " ! python run.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialize\n",
            "device: cuda\n",
            "Loading weights:  model-f46da743.pt\n",
            "Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x8-c38310e5.pth\n",
            "100% 340M/340M [00:09<00:00, 35.9MB/s]\n",
            "start processing\n",
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8joeewwG0Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83487d6-d17f-4d58-e50d-37ce79a336e8"
      },
      "source": [
        "% cd /content/MiDaS/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxzqyQVQqKRp"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import utils\n",
        "import cv2\n",
        "\n",
        "from torchvision.transforms import Compose\n",
        "import torchvision.transforms as transforms\n",
        "from midas.midas_net import MidasNet\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGSpPBO3PBz_"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GWvqH4LdL7g"
      },
      "source": [
        "input_path = \"/content/drive/My Drive/ConstructionPPE/input_images\"\n",
        "output_path = \"output\"\n",
        "# MODEL_PATH = \"model.pt\"\n",
        "model_path = \"model-f46da743.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMe_kwrPLona"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pv9w905PIig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051604a9-0fb2-4385-d6c4-c38ad67bba86"
      },
      "source": [
        "model = MidasNet(model_path, non_negative=True).to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights:  model-f46da743.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLIEhARwBq6b"
      },
      "source": [
        "# print(summary(model.pretrained.layer1, (3, 416, 416)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XSpMUrCEIZ"
      },
      "source": [
        "# print(summary(model.pretrained.layer2, (256, 104, 104)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heMnMvOlCUpq"
      },
      "source": [
        "# print(summary(model.pretrained.layer3, (512, 52, 52)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_rnlqelCitk"
      },
      "source": [
        "# print(summary(model.pretrained.layer4, (1024, 26, 26)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7_RDsMvRE8r"
      },
      "source": [
        "# print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5HVC_osPMyi"
      },
      "source": [
        "from torchsummary import summary\n",
        "print(summary(model, (3, 416, 416)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd_6d_cla1zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4ae576-c061-4f08-af87-3e5e56768b00"
      },
      "source": [
        "print(\"initialize\")\n",
        "\n",
        "# select device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device: %s\" % device)\n",
        "\n",
        "# load network\n",
        "model = MidasNet(model_path, non_negative=True)\n",
        "\n",
        "transform = Compose(\n",
        "    [\n",
        "        \n",
        "        Resize(\n",
        "            608,\n",
        "            608,\n",
        "            resize_target=None,\n",
        "            keep_aspect_ratio=False,\n",
        "            ensure_multiple_of=32,\n",
        "            resize_method=\"upper_bound\",\n",
        "            image_interpolation_method=cv2.INTER_CUBIC,\n",
        "        ),\n",
        "        # transforms.ToTensor(),\n",
        "        NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        PrepareForNet(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
        "num_images = len(img_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialize\n",
            "device: cuda\n",
            "Loading weights:  model-f46da743.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKJ9SI3wa4JN"
      },
      "source": [
        "# from torchsummary import summary\n",
        "# model.to(device)\n",
        "# # sample_image = img_names[0]\n",
        "# img = utils.read_image(sample_image)\n",
        "# img_input = transform({\"image\": img})[\"image\"]\n",
        "# print(img_input.shape)\n",
        "# print(summary(model, input_size = img_input.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtlJkzPW0T57"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTTGETcPvQNu"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPpVHIPEPuWn"
      },
      "source": [
        "\n",
        "\n",
        "class ConstructionPPE(Dataset):\n",
        "\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "\n",
        "        super(ConstructionPPE, self).__init__()\n",
        "        self.data, self.target = [], []\n",
        "        self._load_data(200)\n",
        "        \n",
        "\n",
        "    def _load_data(self, lim):\n",
        "        i = 0\n",
        "        with open(os.path.join(self.path, 'input_file_dir.txt')) as f:\n",
        "            for line in f.readlines():\n",
        "                if i > lim:\n",
        "                    break\n",
        "                i += 1\n",
        "                line = line.strip()\n",
        "                imgs = os.path.join(self.path, 'Annotated Images/' + line)\n",
        "                # print(imgs)\n",
        "                image = Image.open(imgs)\n",
        "                img_input = image.resize((384, 384), 2)\n",
        "                trans = transforms.ToTensor()\n",
        "                img_input = trans(np.array(img_input))\n",
        "                self.data.append(img_input)\n",
        "        \n",
        "        i = 0\n",
        "        with open(os.path.join(self.path, 'MiDaS_file_dir.txt')) as f:\n",
        "            for line in f.readlines():\n",
        "                if i > lim:\n",
        "                    break\n",
        "                i += 1\n",
        "                line = line.strip()\n",
        "                imgs = os.path.join(self.path, line)\n",
        "                # print(imgs)\n",
        "                image = Image.open(imgs)\n",
        "                # transforms = Compose(\n",
        "                #     [\n",
        "                #         transforms.ResizeToTensor(),\n",
        "                #         Resize(\n",
        "                #             384,\n",
        "                #             384,\n",
        "                #             resize_target=None,\n",
        "                #             keep_aspect_ratio=False,\n",
        "                #             ensure_multiple_of=32,\n",
        "                #             resize_method=\"upper_bound\",\n",
        "                #             image_interpolation_method=cv2.INTER_CUBIC,\n",
        "                #         )\n",
        "                #     ]\n",
        "                # )\n",
        "                # img_input = transform({\"image\": image})[\"image\"]\n",
        "                img_input = image.resize((384, 384), 2)\n",
        "                # print(img_input.size)\n",
        "                trans = transforms.ToTensor()\n",
        "                img_input = trans(np.array(img_input))\n",
        "                img_input = np.array(img_input).astype(np.float32) / 65536\n",
        "                # print(len(img_input.split()))\n",
        "                self.target.append(img_input)\n",
        "        \n",
        "    def get_data(self):\n",
        "        return list(zip(self.data, self.target))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.data[idx]\n",
        "        label_name = self.target[idx]\n",
        "        image = Image.open(image_name)\n",
        "        label = Image.open(label_name)\n",
        "        return (image, label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRQm66TPwK-"
      },
      "source": [
        "\n",
        "def data_loader(data, shuffle=True, batch_size=1, num_workers=1, cuda=False):\n",
        "\n",
        "    loader_args = {\n",
        "        'shuffle': shuffle,\n",
        "        'batch_size': batch_size\n",
        "    }\n",
        "\n",
        "    # If GPU exists\n",
        "    if cuda:\n",
        "        loader_args['num_workers'] = num_workers\n",
        "        loader_args['pin_memory'] = True\n",
        "    \n",
        "    return DataLoader(data, **loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmFAjxJ5psuT"
      },
      "source": [
        "dataclass = ConstructionPPE(\"/content/drive/My Drive/ConstructionPPE/\")\n",
        "dataset = dataclass.get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGFB3eSWW0Bi"
      },
      "source": [
        "# from torchvision import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVD21pDkWWe0"
      },
      "source": [
        "# dataset = datasets.ImageFolder(root='ConstructionPPE/', transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAIdwXPruOsG"
      },
      "source": [
        "loader = data_loader(dataset, shuffle=True, batch_size = 4, num_workers=16, cuda = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_sEUP2my0G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6ba249-e203-4890-9357-7d412d73164a"
      },
      "source": [
        "sample = next(iter(loader))\n",
        "print(len(sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9qJWdLN48V3"
      },
      "source": [
        "print(sample[0])\n",
        "print('label now..')\n",
        "print(sample[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLEN1I-yk5x"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG7XiIOayZ2Q"
      },
      "source": [
        "ssim = SSIM()\n",
        "criterion = ssim.to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpais-oDyv5c"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If9yiWuxa7ZA"
      },
      "source": [
        "def train(model, loader, device, optimizer, criterion, l1_factor=0.0):\n",
        "    model.train()\n",
        "    pbar = tqdm(loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar, 0):\n",
        "        # Get samples\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set gradients to zero before starting backpropagation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict output\n",
        "        y_pred = model(data)\n",
        "        # target = target.squeeze()\n",
        "        # y_pred = y_pred.squeeze()\n",
        "        # Calculate loss\n",
        "        # print(y_pred.shape, target.shape)\n",
        "        # print(y_pred)\n",
        "        # print(target)\n",
        "        target = target.float()\n",
        "        y_pred = torch.unsqueeze(y_pred, 1)\n",
        "        loss = criterion(y_pred, target)    \n",
        "        # loss += l1_regularization(model, l1_factor)\n",
        "\n",
        "        # Perform backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update Progress Bar\n",
        "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
        "        # correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "        pbar.set_description(\n",
        "            desc=f'Loss={loss.item():0.2f} Batch_ID={batch_idx}'\n",
        "        )\n",
        "    print('total loss:', loss)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfJardFXeoH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b431564-6ac4-43ae-9fb0-db35a081f958"
      },
      "source": [
        "for i in range(0, 4):\n",
        "    train(model, loader, device, optimizer, criterion, l1_factor = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss=0.00 Batch_ID=50: 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss: tensor(5.9835e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.00 Batch_ID=50: 100%|██████████| 51/51 [00:51<00:00,  1.00s/it]\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss: tensor(4.4403e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.00 Batch_ID=50: 100%|██████████| 51/51 [00:51<00:00,  1.01s/it]\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss: tensor(8.8404e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.00 Batch_ID=50: 100%|██████████| 51/51 [00:51<00:00,  1.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss: tensor(3.9374e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXec-zyxy_r3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}