{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midas + planercnn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubC4IgFIUJ0f",
        "outputId": "0c2d53fc-4f1f-4109-8079-949da0c7d3f8"
      },
      "source": [
        "# ! git clone https://github.com/intel-isl/MiDaS.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MiDaS'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 394 (delta 58), reused 201 (delta 37), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (394/394), 231.02 KiB | 381.00 KiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxOnGCnIUpmu",
        "outputId": "ed5c7af6-80cd-40dd-f646-fc542238ec2c"
      },
      "source": [
        "% cd /content/MiDaS/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptB7s42CyJ38"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import utils\n",
        "import cv2\n",
        "\n",
        "from midas.midas_net import MidasNet\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XcMRK_SygIO",
        "outputId": "f447fc93-0cf7-44d6-dfbd-828d16bbb1c0"
      },
      "source": [
        "model_path = None\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MidasNet(model_path, non_negative=True).to('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFnLynKvyrlV"
      },
      "source": [
        "backbone = model.pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKGMWCKUzCce"
      },
      "source": [
        "# ! git clone https://github.com/ajithvallabai/planercnn_customimages.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiox0gfu1c2r",
        "outputId": "bda5e54e-4e7d-4104-eb62-5646a96ac7d5"
      },
      "source": [
        "% cd planercnn_customimages/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS/planercnn_customimages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFCqXbL-7d96"
      },
      "source": [
        "# ! pip3 install cffi==1.11.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT236EAf2LoQ"
      },
      "source": [
        "from models.model import *\n",
        "from utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpqqC-XUBscb",
        "outputId": "8054056e-4cf6-4863-898f-28129aa993a4"
      },
      "source": [
        "% cd /content/MiDaS/planercnn_customimages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MiDaS/planercnn_customimages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRVvTIWCE0Sq"
      },
      "source": [
        "class FPN(nn.Module):\n",
        "    def __init__(self, C2, C3, C4, C5, out_channels, bilinear_upsampling=False):\n",
        "        super(FPN, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.bilinear_upsampling = bilinear_upsampling\n",
        "        self.C2 = C2\n",
        "        self.C3 = C3\n",
        "        self.C4 = C4\n",
        "        self.C5 = C5\n",
        "        self.P6 = nn.MaxPool2d(kernel_size=1, stride=2)\n",
        "        self.P5_conv1 = nn.Conv2d(2048, self.out_channels, kernel_size=1, stride=1)\n",
        "        self.P5_conv2 = nn.Sequential(\n",
        "            SamePad2d(kernel_size=3, stride=1),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1),\n",
        "        )\n",
        "        self.P4_conv1 =  nn.Conv2d(1024, self.out_channels, kernel_size=1, stride=1)\n",
        "        self.P4_conv2 = nn.Sequential(\n",
        "            SamePad2d(kernel_size=3, stride=1),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1),\n",
        "        )\n",
        "        self.P3_conv1 = nn.Conv2d(512, self.out_channels, kernel_size=1, stride=1)\n",
        "        self.P3_conv2 = nn.Sequential(\n",
        "            SamePad2d(kernel_size=3, stride=1),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1),\n",
        "        )\n",
        "        self.P2_conv1 = nn.Conv2d(256, self.out_channels, kernel_size=1, stride=1)\n",
        "        self.P2_conv2 = nn.Sequential(\n",
        "            SamePad2d(kernel_size=3, stride=1),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.C2(x)\n",
        "        c2_out = x\n",
        "        x = self.C3(x)\n",
        "        c3_out = x\n",
        "        x = self.C4(x)\n",
        "        c4_out = x\n",
        "        x = self.C5(x)\n",
        "        p5_out = self.P5_conv1(x)\n",
        "        \n",
        "        if self.bilinear_upsampling:\n",
        "            p4_out = self.P4_conv1(c4_out) + F.upsample(p5_out, scale_factor=2, mode='bilinear')\n",
        "            p3_out = self.P3_conv1(c3_out) + F.upsample(p4_out, scale_factor=2, mode='bilinear')\n",
        "            p2_out = self.P2_conv1(c2_out) + F.upsample(p3_out, scale_factor=2, mode='bilinear')\n",
        "        else:\n",
        "            p4_out = self.P4_conv1(c4_out) + F.upsample(p5_out, scale_factor=2)\n",
        "            p3_out = self.P3_conv1(c3_out) + F.upsample(p4_out, scale_factor=2)\n",
        "            p2_out = self.P2_conv1(c2_out) + F.upsample(p3_out, scale_factor=2)\n",
        "            pass\n",
        "\n",
        "        p5_out = self.P5_conv2(p5_out)\n",
        "        p4_out = self.P4_conv2(p4_out)\n",
        "        p3_out = self.P3_conv2(p3_out)\n",
        "        p2_out = self.P2_conv2(p2_out)\n",
        "\n",
        "        ## P6 is used for the 5th anchor scale in RPN. Generated by\n",
        "        ## subsampling from P5 with stride of 2.\n",
        "        p6_out = self.P6(p5_out)\n",
        "\n",
        "        return [p2_out, p3_out, p4_out, p5_out, p6_out]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YfggzUNGSPo"
      },
      "source": [
        "l1, l2, l3, l4 = backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ubgzC8wEXNr"
      },
      "source": [
        "fpn = FPN(l1, l2, l3, l4, out_channels=256, bilinear_upsampling=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrSkMLxVGO1H",
        "outputId": "8533f3fe-aaf6-4be9-b0c8-dc7027c7f493"
      },
      "source": [
        "from torchsummary import summary\n",
        "print(summary(fpn, (3, 384, 384)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5          [-1, 256, 64, 64]          16,384\n",
            "       BatchNorm2d-6          [-1, 256, 64, 64]             512\n",
            "              ReLU-7          [-1, 256, 64, 64]               0\n",
            "            Conv2d-8          [-1, 256, 64, 64]          18,432\n",
            "       BatchNorm2d-9          [-1, 256, 64, 64]             512\n",
            "             ReLU-10          [-1, 256, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]          65,536\n",
            "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
            "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
            "             ReLU-15          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
            "           Conv2d-17          [-1, 256, 64, 64]          65,536\n",
            "      BatchNorm2d-18          [-1, 256, 64, 64]             512\n",
            "             ReLU-19          [-1, 256, 64, 64]               0\n",
            "           Conv2d-20          [-1, 256, 64, 64]          18,432\n",
            "      BatchNorm2d-21          [-1, 256, 64, 64]             512\n",
            "             ReLU-22          [-1, 256, 64, 64]               0\n",
            "           Conv2d-23          [-1, 256, 64, 64]          65,536\n",
            "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
            "             ReLU-25          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
            "           Conv2d-27          [-1, 256, 64, 64]          65,536\n",
            "      BatchNorm2d-28          [-1, 256, 64, 64]             512\n",
            "             ReLU-29          [-1, 256, 64, 64]               0\n",
            "           Conv2d-30          [-1, 256, 64, 64]          18,432\n",
            "      BatchNorm2d-31          [-1, 256, 64, 64]             512\n",
            "             ReLU-32          [-1, 256, 64, 64]               0\n",
            "           Conv2d-33          [-1, 256, 64, 64]          65,536\n",
            "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
            "             ReLU-35          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
            "           Conv2d-37          [-1, 512, 64, 64]         131,072\n",
            "      BatchNorm2d-38          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-39          [-1, 512, 64, 64]               0\n",
            "           Conv2d-40          [-1, 512, 32, 32]          73,728\n",
            "      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-42          [-1, 512, 32, 32]               0\n",
            "           Conv2d-43          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
            "           Conv2d-49          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-51          [-1, 512, 32, 32]               0\n",
            "           Conv2d-52          [-1, 512, 32, 32]          73,728\n",
            "      BatchNorm2d-53          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-54          [-1, 512, 32, 32]               0\n",
            "           Conv2d-55          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
            "           Conv2d-59          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-61          [-1, 512, 32, 32]               0\n",
            "           Conv2d-62          [-1, 512, 32, 32]          73,728\n",
            "      BatchNorm2d-63          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-64          [-1, 512, 32, 32]               0\n",
            "           Conv2d-65          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
            "           Conv2d-69          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-70          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-71          [-1, 512, 32, 32]               0\n",
            "           Conv2d-72          [-1, 512, 32, 32]          73,728\n",
            "      BatchNorm2d-73          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-74          [-1, 512, 32, 32]               0\n",
            "           Conv2d-75          [-1, 512, 32, 32]         262,144\n",
            "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
            "           Conv2d-79         [-1, 1024, 32, 32]         524,288\n",
            "      BatchNorm2d-80         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-81         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-82         [-1, 1024, 16, 16]         294,912\n",
            "      BatchNorm2d-83         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-84         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-85         [-1, 1024, 16, 16]       1,048,576\n",
            "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
            "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-89         [-1, 1024, 16, 16]               0\n",
            "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-91         [-1, 1024, 16, 16]       1,048,576\n",
            "      BatchNorm2d-92         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-93         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-94         [-1, 1024, 16, 16]         294,912\n",
            "      BatchNorm2d-95         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-96         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-97         [-1, 1024, 16, 16]       1,048,576\n",
            "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-99         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-101         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-102         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-103         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-104         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-105         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-106         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-107         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-109         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-111         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-112         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-113         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-114         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-115         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-116         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-117         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-119         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-121         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-122         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-123         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-124         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-125         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-126         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-127         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-129         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-131         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-132         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-133         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-134         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-135         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-136         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-137         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-139         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-141         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-142         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-143         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-144         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-145         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-146         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-147         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-148         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-149         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-150         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-151         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-152         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-153         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-154         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-155         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-156         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-157         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-158         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-159         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-160         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-161         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-162         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-163         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-164         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-165         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-166         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-167         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-168         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-169         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-170         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-171         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-172         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-173         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-174         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-175         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-176         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-177         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-178         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-179         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-180         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-181         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-182         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-183         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-184         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-185         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-186         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-187         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-188         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-189         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-190         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-191         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-192         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-193         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-194         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-195         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-196         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-197         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-198         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-199         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-200         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-201         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-202         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-203         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-204         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-205         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-206         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-207         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-208         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-209         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-210         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-211         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-212         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-213         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-214         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-215         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-216         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-217         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-218         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-219         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-220         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-221         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-222         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-223         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-224         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-225         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-226         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-227         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-228         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-229         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-230         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-231         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-232         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-233         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-234         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-235         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-236         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-237         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-239         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-240         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-241         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-242         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-243         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-244         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-245         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-246         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-247         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-248         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-249         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-250         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-251         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-252         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-253         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-254         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-255         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-256         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-257         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-259         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-260         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-261         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-262         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-263         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-264         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-265         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-266         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-267         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-268         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-269         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-270         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-271         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-272         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-273         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-274         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-275         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-276         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-277         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-278         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-279         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-280         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-281         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-282         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-283         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-284         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-285         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-286         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-287         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-288         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-289         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-290         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-291         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-292         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-293         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-294         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-295         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-296         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-297         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-298         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-299         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-300         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-301         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-302         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-303         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-304         [-1, 1024, 16, 16]         294,912\n",
            "     BatchNorm2d-305         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-306         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-307         [-1, 1024, 16, 16]       1,048,576\n",
            "     BatchNorm2d-308         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-309         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-310         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-311         [-1, 2048, 16, 16]       2,097,152\n",
            "     BatchNorm2d-312         [-1, 2048, 16, 16]           4,096\n",
            "            ReLU-313         [-1, 2048, 16, 16]               0\n",
            "          Conv2d-314           [-1, 2048, 8, 8]       1,179,648\n",
            "     BatchNorm2d-315           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-316           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-317           [-1, 2048, 8, 8]       4,194,304\n",
            "     BatchNorm2d-318           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-319           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-320           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-321           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-322           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-323           [-1, 2048, 8, 8]       4,194,304\n",
            "     BatchNorm2d-324           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-325           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-326           [-1, 2048, 8, 8]       1,179,648\n",
            "     BatchNorm2d-327           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-328           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-329           [-1, 2048, 8, 8]       4,194,304\n",
            "     BatchNorm2d-330           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-331           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-332           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-333           [-1, 2048, 8, 8]       4,194,304\n",
            "     BatchNorm2d-334           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-335           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-336           [-1, 2048, 8, 8]       1,179,648\n",
            "     BatchNorm2d-337           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-338           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-339           [-1, 2048, 8, 8]       4,194,304\n",
            "     BatchNorm2d-340           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-341           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-342           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-343            [-1, 256, 8, 8]         524,544\n",
            "          Conv2d-344          [-1, 256, 16, 16]         262,400\n",
            "          Conv2d-345          [-1, 256, 32, 32]         131,328\n",
            "          Conv2d-346          [-1, 256, 64, 64]          65,792\n",
            "       SamePad2d-347          [-1, 256, 10, 10]               0\n",
            "          Conv2d-348            [-1, 256, 8, 8]         590,080\n",
            "       SamePad2d-349          [-1, 256, 18, 18]               0\n",
            "          Conv2d-350          [-1, 256, 16, 16]         590,080\n",
            "       SamePad2d-351          [-1, 256, 34, 34]               0\n",
            "          Conv2d-352          [-1, 256, 32, 32]         590,080\n",
            "       SamePad2d-353          [-1, 256, 66, 66]               0\n",
            "          Conv2d-354          [-1, 256, 64, 64]         590,080\n",
            "       MaxPool2d-355            [-1, 256, 4, 4]               0\n",
            "================================================================\n",
            "Total params: 90,086,720\n",
            "Trainable params: 90,086,720\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 1041.88\n",
            "Params size (MB): 343.65\n",
            "Estimated Total Size (MB): 1386.28\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "m6mBbabt6_HU",
        "outputId": "8358cad3-1f45-4afc-fa51-2ca206a2e82d"
      },
      "source": [
        "# from config import PlaneConfig\n",
        "\n",
        "# model = MaskRCNN(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6f9eaf198265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlaneConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model = MaskRCNN(config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MiDaS/planercnn_customimages/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# the configurations you need to change.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \"\"\"Base configuration class. For custom configurations, create a\n\u001b[1;32m     19\u001b[0m     \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mthat\u001b[0m \u001b[0minherits\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MiDaS/planercnn_customimages/config.py\u001b[0m in \u001b[0;36mConfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Image mean (RGB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mMEAN_PIXEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m123.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m116.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m103.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mMEAN_PIXEL_TENSOR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMEAN_PIXEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Number of ROIs per image to feed to classifier/mask heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ3vbAq-430"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}